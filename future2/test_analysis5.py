# test_analysis.py

import logging
from typing import Dict, Any, List
from llm_client import get_llm_client
from vector_store import VectorStore
from text_processor import TextProcessor
from logger_config import setup_logger
import tiktoken
import json

logger = setup_logger("test_analysis")

def count_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
        return len(text.split()) * 1.3

def calculate_chunk_size(materials: List[Dict[str, Any]], max_context_size: int) -> int:
    available_tokens = int(max_context_size * 0.8)
    total_tokens = sum(count_tokens(material['text']) for material in materials)
    avg_tokens = total_tokens / len(materials)
    return max(1, int(available_tokens / avg_tokens))

def _create_context_aware_chunks(materials: List[Dict[str, Any]], max_context_size: int) -> List[List[Dict[str, Any]]]:
    chunks, current_chunk, current_size = [], [], 0
    chunk_size = calculate_chunk_size(materials, max_context_size)

    for material in materials:
        tokens = count_tokens(material['text'])
        if current_size + tokens > max_context_size * 0.8:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = [material]
            current_size = tokens
        else:
            current_chunk.append(material)
            current_size += tokens

        if len(current_chunk) >= chunk_size:
            chunks.append(current_chunk)
            current_chunk, current_size = [], 0

    if current_chunk:
        chunks.append(current_chunk)

    return chunks

def test_embeddings():
    try:
        text_processor = TextProcessor(
            embedding_type="openai",
            openai_model="text-embedding-3-small"
        )
        embedding = text_processor.create_embeddings(["Test embedding"])[0]
        logger.info(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {len(embedding)}")
        return len(embedding)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {str(e)}")
        return None

def analyze_trend(
    category: str,
    user_query: str,
    embedding_type: str = "openai",
    openai_model: str = "text-embedding-3-small"
) -> Dict[str, Any]:
    try:
        llm_client = get_llm_client()
        vector_store = VectorStore(
            embedding_type=embedding_type,
            openai_model=openai_model
        )
        text_processor = TextProcessor(
            embedding_type=embedding_type,
            openai_model=openai_model
        )

        theme_prompt = f"""
        –¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Å—Ñ–µ—Ä–µ {category}.
        –ù–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

        –ó–∞–ø—Ä–æ—Å: {user_query}

        –í—ã–¥–µ–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ç–µ–º—É, –∏–≥—Ä—É, –ø—Ä–æ–¥—É–∫—Ç, —Å–æ–±—ã—Ç–∏–µ –∏–ª–∏ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.
        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —ç—Ç—É —Ç–µ–º—É/—Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–µ, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
        """
        theme = llm_client.analyze_text(theme_prompt, user_query).get('analysis', '').strip()
        logger.info(f"–¢–µ–º–∞ –∑–∞–ø—Ä–æ—Å–∞: {theme}")

        search_embedding = text_processor.create_embeddings([theme])[0]
        relevant_materials = vector_store.search_vectors(
            query_vector=search_embedding,
            category=category,
            score_threshold=0.30
        )

        if not relevant_materials:
            logger.warning("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤")
            return {'status': 'error', 'message': '–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤'}

        max_context_size = llm_client.get_max_context_size()
        total_tokens = sum(count_tokens(m['text']) for m in relevant_materials)

        if total_tokens <= max_context_size * 0.8:
            filter_prompt = f"""
            –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Å—Ñ–µ—Ä–µ {category}. –ù–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ —Ç–µ–º–µ "{theme}" –∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

            –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query}

            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –û—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ —Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (text –∏ url), –∫–æ—Ç–æ—Ä—ã–µ –æ—á–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –∑–∞–ø—Ä–æ—Å—É –∏ —Ç–µ–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–≥—Ä–µ, —Å–æ–±—ã—Ç–∏—é, —Ä–µ–ª–∏–∑—É, –ø–∞—Ç—á—É, –º–µ—Ç—Ä–∏–∫–∞–º –∏ —Ç.–¥.). –ò—Å–∫–ª—é—á–∏ –æ–±–æ–±—â–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
            –û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ –°–¢–†–û–ì–û –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π: [{{"text": "...", "url": "..."}}]
            –ï—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫: []
            """
            filtered_materials_str = llm_client.analyze_text(filter_prompt, user_query).get('analysis', '')
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ —Å—Ç—Ä–æ–∫–∏
            try:
                filtered_materials = json.loads(filtered_materials_str)
                if not isinstance(filtered_materials, list):
                    filtered_materials = [] # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–ª–∏ –µ—Å–ª–∏ –Ω–µ —Å–ø–∏—Å–æ–∫
            except json.JSONDecodeError:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∫–∞–∫ JSON: {filtered_materials_str}")
                filtered_materials = [] # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞

            if not filtered_materials:
                logger.warning("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤")
                return {'status': 'error', 'message': '–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏'}

            analysis_prompt = f"""
            –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä—ã–Ω–∫–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ —Ç–µ–º–µ "{theme}" –≤ —Å—Ñ–µ—Ä–µ {category}:

            –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query}

            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã:
            {filtered_materials}

            –ü—Ä–æ–≤–µ–¥–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–æ—Å—Ç–∞–≤—å –æ—Ç—á–µ—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –º–µ—Ç—Ä–∏–∫–∞—Ö (GMV, ADV, ETR, AOV, Orders, CR, ADV/GM), –ø—Ä–∏—á–∏–Ω–∞—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–ø—Ä–æ—Å–∞/–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ), –∏ —á–µ—Ç–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö.

            –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á–µ—Ç–∞:
            –¢—Ä–µ–Ω–¥—ã –∏ –°–æ–±—ã—Ç–∏—è (—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç):
            - –ö—Ä–∞—Ç–∫–æ, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ (–¥–∞—Ç–∞, —Å—É—Ç—å)
            - –°—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö)

            –í–ª–∏—è–Ω–∏–µ –∏ –ú–µ—Ç—Ä–∏–∫–∏:
            - –ö–∞–∫ —Å–æ–±—ã—Ç–∏–µ –ø–æ–≤–ª–∏—è–ª–æ –Ω–∞ –ø—Ä–æ–¥–∞–∂–∏, –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏–≥—Ä–æ–∫–æ–≤/–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Ü–µ–Ω—ã, –º–µ—Ç—Ä–∏–∫–∏ (GMV, ADV, CR –∏ —Ç.–¥.). –£–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å.
            - –û–±—â–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è (—Ñ–æ—Ä—É–º—ã, —Å–æ—Ü—Å–µ—Ç–∏, —Å—Ç—Ä–∏–º–µ—Ä—ã - –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç–æ –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö).

            –ê–Ω–∞–ª–∏–∑ –∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞:
            - –ê–Ω–∞–ª–∏–∑ —Å–∏—Ç—É–∞—Ü–∏–∏ (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º–∏, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –¶–ê, —Ü–µ–Ω—ã).
            - –ß–µ—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: —á—Ç–æ –¥–µ–ª–∞—Ç—å, –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–ø—É—Å–∫ –∞–∫—Ü–∏–∏, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π —É—Å–ª—É–≥–∏, —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç.–¥.).

            –°–¥–µ–ª–∞–π –æ—Ç—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –±–∏–∑–Ω–µ—Å-—Ä–µ—à–µ–Ω–∏–π.
            """
            final_analysis = llm_client.analyze_text(analysis_prompt, user_query)
            return {'status': 'ok', 'report': final_analysis.get('analysis', '')}

        else:
            chunks = _create_context_aware_chunks(relevant_materials, max_context_size)
            chunk_analyses_texts = [] # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç—ã –∞–Ω–∞–ª–∏–∑–æ–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è

            for i, chunk in enumerate(chunks):
                chunk_filter_prompt = f"""
                –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Å—Ñ–µ—Ä–µ {category}. –ù–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ (—á–∞—Å—Ç—å {i+1}/{len(chunks)}) –ø–æ —Ç–µ–º–µ "{theme}" –∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

                –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query}

                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –û—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ —Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (text –∏ url), –∫–æ—Ç–æ—Ä—ã–µ –æ—á–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –∑–∞–ø—Ä–æ—Å—É –∏ —Ç–µ–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–≥—Ä–µ, —Å–æ–±—ã—Ç–∏—é, —Ä–µ–ª–∏–∑—É, –ø–∞—Ç—á—É, –º–µ—Ç—Ä–∏–∫–∞–º –∏ —Ç.–¥.). –ò—Å–∫–ª—é—á–∏ –æ–±–æ–±—â–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
                –û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ –°–¢–†–û–ì–û –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π: [{{"text": "...", "url": "..."}}]
                –ï—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫: []
                """
                filtered_chunk_materials_str = llm_client.analyze_text(chunk_filter_prompt, user_query).get('analysis', '')
                try:
                    filtered_chunk_materials = json.loads(filtered_chunk_materials_str)
                    if not isinstance(filtered_chunk_materials, list):
                        filtered_chunk_materials = []
                except json.JSONDecodeError:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã —á–∞–Ω–∫–∞ {i+1} –∫–∞–∫ JSON: {filtered_chunk_materials_str}")
                    filtered_chunk_materials = []

                if not filtered_chunk_materials:
                    logger.warning(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤ —á–∞–Ω–∫–µ {i+1} –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤")
                    continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç —á–∞–Ω–∫, –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤

                chunk_analysis_prompt = f"""
                –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ä—ã–Ω–∫–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ (—á–∞—Å—Ç—å {i+1}/{len(chunks)}) –ø–æ —Ç–µ–º–µ "{theme}" –≤ —Å—Ñ–µ—Ä–µ {category}:

                –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏–∑ —á–∞–Ω–∫–∞:
                {filtered_chunk_materials}

                –ü—Ä–æ–≤–µ–¥–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –º–µ—Ç—Ä–∏–∫–∞—Ö (GMV, ADV, ETR, AOV, Orders, CR, ADV/GM), –ø—Ä–∏—á–∏–Ω–∞—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–ø—Ä–æ—Å–∞/–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ —ç—Ç–æ–º —á–∞–Ω–∫–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.

                –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è):
                –¢—Ä–µ–Ω–¥—ã –∏ –°–æ–±—ã—Ç–∏—è (—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç):
                - –ö—Ä–∞—Ç–∫–æ, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ (–¥–∞—Ç–∞, —Å—É—Ç—å)
                - –°—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö)

                –í–ª–∏—è–Ω–∏–µ –∏ –ú–µ—Ç—Ä–∏–∫–∏:
                - –ö–∞–∫ —Å–æ–±—ã—Ç–∏–µ –ø–æ–≤–ª–∏—è–ª–æ –Ω–∞ –ø—Ä–æ–¥–∞–∂–∏, –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, —Ü–µ–Ω—ã, –º–µ—Ç—Ä–∏–∫–∏. –£–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ—Å—Ç—å.
                - –û–±—â–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è (–µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç–æ).

                –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
                - –ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å, –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ, –∏—Å—Ö–æ–¥—è –∏–∑ —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞.

                –°–¥–µ–ª–∞–π –∞–Ω–∞–ª–∏–∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º. –ï—Å–ª–∏ –≤ —á–∞–Ω–∫–µ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–∏–º –ø—É–Ω–∫—Ç–∞–º, –Ω–∞–ø–∏—à–∏ —ç—Ç–æ —è–≤–Ω–æ.
                """
                analysis = llm_client.analyze_text(chunk_analysis_prompt, user_query).get('analysis', '')
                chunk_analyses_texts.append(analysis)

            if not chunk_analyses_texts:
                 logger.warning("–ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —á–∞–Ω–∫–æ–≤ –Ω–µ –ø–æ–ª—É—á–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")
                 return {'status': 'error', 'message': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤'}

            separator = '\n\n---\n\n'
            final_prompt = f"""
            –¢—ã - –≥–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Å—Ñ–µ—Ä–µ {category}. –û–±—ä–µ–¥–∏–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –ø–æ —Ç–µ–º–µ "{theme}" –≤ –µ–¥–∏–Ω—ã–π, —Å–≤—è–∑–Ω—ã–π –∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç. –û—Å–Ω–æ–≤—ã–≤–∞–π—Å—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query}.

            –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è:
            {separator.join(chunk_analyses_texts)}

            –°–æ—Å—Ç–∞–≤—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞. –í–∫–ª—é—á–∏ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤, —É—Å—Ç—Ä–∞–Ω–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π –≤—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.

            –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞:
            –û–±—â–∏–π –û–±–∑–æ—Ä –∏ –ö–ª—é—á–µ–≤—ã–µ –¢—Ä–µ–Ω–¥—ã (–ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏/–ø—Ä–æ–¥—É–∫—Ç—É):
            - –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤.

            –î–µ—Ç–∞–ª—å–Ω—ã–π –ê–Ω–∞–ª–∏–∑ –í–ª–∏—è–Ω–∏—è –∏ –ú–µ—Ç—Ä–∏–∫–∏:
            - –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –ø—Ä–æ–¥–∞–∂–∏, –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, —Ü–µ–Ω—ã, –º–µ—Ç—Ä–∏–∫–∏ (GMV, ADV, CR, –∏ —Ç.–¥.) —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ.
            - –û–±—â–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏.

            –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –ê–Ω–∞–ª–∏–∑ –∏ –†—ã–Ω–æ—á–Ω–∞—è –°–∏—Ç—É–∞—Ü–∏—è:
            - –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã –ø–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º –∏ —Ä—ã–Ω–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.

            –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–≥–æ –ú–µ–Ω–µ–¥–∂–µ—Ä–∞:
            - –ß–µ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –¥–µ–π—Å—Ç–≤–∏–π (–∑–∞–ø—É—Å–∫ –Ω–æ–≤—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤/—É—Å–ª—É–≥, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω–æ–≤–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ —Ç.–¥.), –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—Å–µ–º –∞–Ω–∞–ª–∏–∑–µ.

            –°–¥–µ–ª–∞–π –æ—Ç—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω–∏–º—ã–º –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.
            """
            final_report = llm_client.analyze_text(final_prompt, user_query).get('analysis', '')
            return {'status': 'ok', 'report': final_report}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
        return {'status': 'error', 'message': str(e)}


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    embedding_size = test_embeddings()
    if embedding_size:
        logger.info(f"‚úÖ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embedding_size}")

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
    category = "–í–∏–¥–µ–æ–∏–≥—Ä—ã"
    user_query = (
        "–û–ø—Ä–µ–¥–µ–ª–∏ —Ç–µ–∫—É—â–∏–µ —Ç—Ä–µ–Ω–¥—ã —Å–ø—Ä–æ—Å–∞ –Ω–∞ –≤–Ω—É—Ç—Ä–∏–∏–≥—Ä–æ–≤—ã–µ –ø—Ä–µ–¥–º–µ—Ç—ã –¥–ª—è 'Dota 2' (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å—É–Ω–¥—É–∫–∏, –∫–ª—é—á–∏, —Å–µ—Ç—ã). –ö–∞–∫–∏–µ —Ç–∏–ø—ã –ø—Ä–µ–¥–º–µ—Ç–æ–≤ —Å–µ–π—á–∞—Å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã, –∏" 
        "–µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–º, –∫–∞–∫–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã –∞–∫—Ç–∏–≤–Ω–æ –ø—Ä–æ–¥–∞—é—Ç —ç—Ç–∏ —Ç–æ–≤–∞—Ä—ã? –ü—Ä–µ–¥–ª–æ–∂–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞."
        )

    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category} –∏ –∑–∞–ø—Ä–æ—Å–∞: {user_query}")
    result = analyze_trend(category, user_query)

    if result['status'] == 'ok':
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(result['report'])
    else:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['message']}")
